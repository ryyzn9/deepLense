{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCqIqbb8Btko",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# DeepLense Regression\n",
    "\n",
    "A FastAI-based tool for performing regression on strong lensing images to predict axion mass density of galaxies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image is = \n",
      "(22500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the process is running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the process is running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import sys\n",
    "# setting path\n",
    "sys.path.append('../utils')\n",
    "\n",
    "image_shape = (150, 150)\n",
    "\n",
    "\n",
    "from utils.utils import dir_path\n",
    "sys.path.append(r'\\Users\\91963\\deepl\\DeepLense-Regression\\path_Image\\images.npy')\n",
    "sys.path.append(r'\\Users\\91963\\deepl\\DeepLense-Regression\\path_Image\\mass_densities.npy')\n",
    "\n",
    "path_to_images=\"path_Image\"\n",
    "result_path=\"result_dir\"\n",
    "file_names = os.listdir(path_to_images)\n",
    "files_num = len(file_names)\n",
    "img_shape = np.load(os.path.join(path_to_images, file_names[0]), allow_pickle=True)[0].shape\n",
    "print(\"image is = \")\n",
    "print(img_shape)\n",
    "# Create base mmep_map on the disk where we will be writting the files\n",
    "images_mmep = np.memmap(os.path.join(result_path,'images_mmep.npy'),\n",
    "                        dtype='int16',\n",
    "                        mode='w+',\n",
    "                        shape=(files_num,*img_shape))\n",
    "\n",
    "masses_mmep = np.memmap(os.path.join(result_path,'masses_mmep.npy'),\n",
    "                        dtype='float32',\n",
    "                        mode='w+',\n",
    "                        shape=(files_num,1))\n",
    "\n",
    "# Index that shows which part of the file is being written to\n",
    "w_index = 0\n",
    "for file_name in tqdm(file_names):\n",
    "    img =np.load(r'C:\\Users\\91963\\deepl\\DeepLense-Regression\\path_Image\\images.npy',allow_pickle=True) # np.load(os.path.join(path_to_images, file_name),allow_pickle=True)\n",
    "    mass = np.load(r'C:\\Users\\91963\\deepl\\DeepLense-Regression\\path_Image\\mass_densities.npy',allow_pickle=True)\n",
    "    images_mmep = img[w_index:w_index+1,:]\n",
    "    masses_mmep = mass[w_index:w_index+1,:]\n",
    "    w_index+=1\n",
    "    print(\"the process is running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 22500)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_mmep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masses_mmep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HluHTYZMKp1Y",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "from models.xresnet_hybrid import xresnet_hybrid101\n",
    "from utils.utils import inv_standardize,standardize, file_path, dir_path\n",
    "from utils.custom_activation_functions import Mish_layer\n",
    "from utils.custom_loss_functions import root_mean_squared_error, mae_loss_wgtd\n",
    "from data.custom_datasets import RegressionNumpyArrayDataset\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5k6JCWGNlwrQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GDfKapGYl6WV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_to_images = r'C:\\Users\\91963\\deepl\\DeepLense-Regression\\path_Image\\images.npy'\n",
    "path_to_masses = r'C:\\Users\\91963\\deepl\\DeepLense-Regression\\path_Image\\mass_densities.npy'\n",
    "\n",
    "image_shape = (1,150,150)\n",
    "# Number of images\n",
    "images_num = 25000\n",
    "# Load the dataset\n",
    "# Memmap loads images to RAM only when they are used\n",
    "images = np.memmap(path_to_images,\n",
    "                   dtype='uint16',\n",
    "                   mode='r',\n",
    "                   shape=(images_num,*image_shape))\n",
    "\n",
    "labels = np.memmap(path_to_masses,\n",
    "                   dtype='uint16',\n",
    "                   mode='r',\n",
    "                   shape=(images_num,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eCVJbCunnNil",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of images: (25000, 1, 150, 150)\n",
      "Shape of masses: (25000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of images: {images.shape}')\n",
    "print(f'Shape of masses: {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLDBoF21omFn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lalDUwD-nGPd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(234)\n",
    "num_of_images = labels.shape[0]\n",
    "max_indx_of_train_images = int(num_of_images*0.15)\n",
    "max_indx_of_valid_images = max_indx_of_train_images + int(num_of_images*0.1)\n",
    "max_indx_num_of_test_images = max_indx_of_valid_images + int(num_of_images*0.05)\n",
    "permutated_indx = np.random.permutation(num_of_images)\n",
    "train_indx = permutated_indx[:max_indx_of_train_images]\n",
    "valid_indx = permutated_indx[max_indx_of_train_images:max_indx_of_valid_images]\n",
    "test_indx = permutated_indx[max_indx_of_valid_images:max_indx_num_of_test_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Spf4o2dVoMkS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in train: 3750\n",
      "Number of images in valid: 2500\n",
      "Number of images in test: 1250\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of images in train: {int(num_of_images*0.15)}')\n",
    "print(f'Number of images in valid: {int(num_of_images*0.1)}')\n",
    "print(f'Number of images in test: {int(num_of_images*0.05)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dw5h65rto2ae",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bTHEkFPCo4PE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_image_transforms = [\n",
    "    transforms.Resize(25000, 1, 150, 150)\n",
    "]\n",
    "rotation_image_transofrms = [\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=(0,360))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cB-XIh2pAZB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uQ-tssFppDA3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = RegressionNumpyArrayDataset(images, labels, train_indx,\n",
    "                                            )\n",
    "valid_dataset = RegressionNumpyArrayDataset(images, labels, valid_indx,                                          \n",
    "                                            )\n",
    "test_dataset = RegressionNumpyArrayDataset(images, labels, test_indx,                                 \n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y00Nc8kupUHB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create a DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Pe1RPdMEpWMQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {device}')\n",
    "batch_size = 64\n",
    "dls = DataLoaders.from_dsets(train_dataset,valid_dataset,batch_size=batch_size, device=device, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my code model for testing the all code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOaDMkXtpet-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3RB5zMl5pTUq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(50)\n",
    "model = xresnet_hybrid101(n_out=1, sa=True, act_cls=Mish_layer, c_in = 1,device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b6fgS4hp4CJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create a Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tKF1VwgtorhN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learn = Learner(\n",
    "    dls, \n",
    "    model,\n",
    "    opt_func=ranger, \n",
    "    loss_func= root_mean_squared_error,  \n",
    "    metrics=[mae_loss_wgtd],\n",
    "    model_dir = ''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IX3eOWDfqB6M",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Find a Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yfDbyubnqEJR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='1' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [1/2 15:31&lt;15:31]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='30' class='' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      51.72% [30/58 08:00&lt;07:28 3.6601]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YfvOShQCqANp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mae_loss_wgtd</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='2' class='' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      3.45% [2/58 00:32&lt;15:05 4.6235]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_of_epochs = 1\n",
    "lr = 1e-2\n",
    "learn.fit_one_cycle(num_of_epochs,lr,cbs=\n",
    "                    [ShowGraphCallback,\n",
    "                     SaveModelCallback(monitor='mae_loss_wgtd',fname='best_model')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWGhVrLSsBwK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2jl8XvPjzps",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learn.load('best_model',device=device)\n",
    "learn.model = learn.model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bQHmnknsgr1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Get Predictions for the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9JbpmI0sktm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_dataset, batch_size=1,shuffle=False,device=device)\n",
    "m_pred,m_true = learn.get_preds(dl=test_dl,reorder=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ew5vvLeSs0iu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SjWckOWpogoW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_mae = mae_loss_wgtd(m_pred,m_true)\n",
    "plt.figure(figsize=(6,6),dpi=100)\n",
    "plt.scatter(m_true, m_pred,  color='black')\n",
    "line = np.linspace(0, 6, 100)\n",
    "plt.plot(line, line)\n",
    "plt.xlabel('Observed mass')\n",
    "plt.ylabel('Predicted mass')\n",
    "plt.text(1,4, 'MAE: {:.4f}'.format(test_mae))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "example_notebook.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "94ba651dc4892b9b39eff64f738fac3dc832246874c3417a1cd9874538024232"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('DeepLense-Regression-647Wbmta': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
